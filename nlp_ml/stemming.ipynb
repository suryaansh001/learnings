{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "stemming is the process to breakdown the word to its stem word or root word \n",
    "example ----- >>>>\n",
    "Original Word\tStemmed Word \n",
    "running\tran               ran\n",
    "eating\t                    eat\n",
    "eats\t                    eat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "eat_words=[\"eating\",\"eaten\",\"eat\",\"ate\",\"at\"]\n",
    "go_words=[\"going\",\"gone\",\"go\",\"went\",\"to\"]\n",
    "random_words=[\"history\",\"programming\",\"python\",\"java\",\"c++\",\"javascript\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Portstemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "stemming = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating ------> eat\n",
      "eaten ------> eaten\n",
      "eat ------> eat\n",
      "ate ------> ate\n",
      "at ------> at\n",
      "going ------> go\n",
      "gone ------> gone\n",
      "go ------> go\n",
      "went ------> went\n",
      "to ------> to\n",
      "history ------> histori\n",
      "programming ------> program\n",
      "python ------> python\n",
      "java ------> java\n",
      "c++ ------> c++\n",
      "javascript ------> javascript\n"
     ]
    }
   ],
   "source": [
    "for word in eat_words:\n",
    "    print(word ,\"------>\",stemming.stem(word))\n",
    "for word in go_words:\n",
    "    print(word ,\"------>\",stemming.stem(word))\n",
    "for word in random_words:\n",
    "    print(word ,\"------>\",stemming.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'congratul'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemming.stem('congratulations')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# there are mutliple disadvenatges with port stemmer like \n",
    "Over-Stemming: Produces stems that are overly simplified and lose semantic meaning.\n",
    "\n",
    "Under-Stemming: Fails to reduce words sufficiently, leading to inconsistent results.\n",
    "\n",
    "Inconsistent Results: Different words may be stemmed in ways that don't make sense contextually.\n",
    "\n",
    "Loss of Meaning: Words with different meanings may be reduced to the same root.\n",
    "\n",
    "Handling Irregular Forms: It struggles with irregular word forms like verbs in different tenses.\n",
    "\n",
    "Language Dependency: It is designed for English and does not work well for other languages.\n",
    "\n",
    "No Contextual Awareness: It does not consider the part of speech or meaning of a word in context.\n",
    "\n",
    "Inability to Handle Compound Words: It does not split or process compound words effectively.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import RegexpStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg= RegexpStemmer('ing$|s$|e$|able$', min=4)\n",
    "# for word in eat_words:\n",
    "#     print(word ,\"------>\",reg.stem(word))\n",
    "# for word in go_words:\n",
    "#     print(word ,\"------>\",reg.stem(word))\n",
    "# for word in random_words:\n",
    "#     print(word ,\"------>\",reg.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'un'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.stem('congratulations')\n",
    "reg.stem('unable')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SnowBall Stemmer \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "snowball = SnowballStemmer('english')\n",
    "words=[\"fairly\",\"beauty\",\"congratulations\",\"fairness\",\"fairy\",\"sportingly\",\"sportsmanship\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fairly ------> fair\n",
      "beauty ------> beauti\n",
      "congratulations ------> congratul\n",
      "fairness ------> fair\n",
      "fairy ------> fairi\n",
      "sportingly ------> sport\n",
      "sportsmanship ------> sportsmanship\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word ,\"------>\",snowball.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'goe'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snowball.stem('goes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With stemmer there is always a risk that some might be good enough but may mess woth some words there fore we need lemmetization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmetization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### we have different postags in lemmatization that is specifying the word whether its noun verb etc \n",
    "\n",
    "# noun -n\n",
    "# adjective - a\n",
    "# adverb - r \n",
    "# verb - v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating ------> eat\n",
      "eaten ------> eat\n",
      "eat ------> eat\n",
      "ate ------> eat\n",
      "at ------> at\n",
      "going ------> go\n",
      "gone ------> go\n",
      "go ------> go\n",
      "went ------> go\n",
      "to ------> to\n",
      "history ------> history\n",
      "programming ------> programming\n",
      "python ------> python\n",
      "java ------> java\n",
      "c++ ------> c++\n",
      "javascript ------> javascript\n",
      "fairly ------> fairly\n",
      "beauty ------> beauty\n",
      "congratulations ------> congratulation\n",
      "fairness ------> fairness\n",
      "fairy ------> fairy\n",
      "sportingly ------> sportingly\n",
      "sportsmanship ------> sportsmanship\n"
     ]
    }
   ],
   "source": [
    "for word in eat_words:\n",
    "    print(word ,\"------>\",lemmatizer.lemmatize(word, pos='v'))\n",
    "for word in go_words:\n",
    "    print(word ,\"------>\",lemmatizer.lemmatize(word, pos='v'))\n",
    "for word in random_words:\n",
    "    print(word ,\"------>\",lemmatizer.lemmatize(word,    pos='n'))\n",
    "for word in words:\n",
    "    print(word ,\"------>\",lemmatizer.lemmatize(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
